{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-Cluster Naming Using Quadkeys\n",
    "\n",
    "_Quadkey_ version - Uses Bing Maps Tile System quadkeys to cache the OSM data.\n",
    "\n",
    "In this notebook we will use the locations that were used to create the clusters to match against OpenStreetMap's data in order to derive a human-readable name for each cluster. These clusters are mainly street intersections in Ann Arbor, so names will try and reflect that.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- Please run the `06-cluster-geofencing.ipynb` notebook first and its dependencies.\n",
    "- Recommended install: [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html). Enable using `jupyter nbextension enable --py widgetsnbextension --sys-prefix` for Jupyter Notebook and `jupyter labextension install @jupyter-widgets/jupyterlab-manager` for Jupyter Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import folium\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import folium\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from pyquadkey2 import quadkey\n",
    "from pyquadkey2.quadkey import TileAnchor, QuadKey\n",
    "from folium.vector_layers import PolyLine, CircleMarker\n",
    "from h3 import h3\n",
    "from db.api import VedDb\n",
    "from tqdm.auto import tqdm\n",
    "from osm.models import OSMNode, OSMWay, OSMNet\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object of the `VedDB` type to interface with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = VedDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_cluster_points` retrieves all the geographic locations that define a particular cluster, or endpoint. Note how the single parameter is passed enclosed in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_points(cluster):\n",
    "    sql = \"select latitude, longitude from cluster_point where cluster_id=?\"\n",
    "    return db.query(sql, [cluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the cluster identifiers from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select distinct cluster_id from cluster_point\"\n",
    "clusters = [c[0] for c in db.query(sql)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying OpenStreetMap Data\n",
    "\n",
    "In this section we calculate the cluster names using data from OpenStreetMap's [OverPass API](https://wiki.openstreetmap.org/wiki/Overpass_API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by calculating all the clusters' bounding boxes, using the code below. Each bounding box delimits the query to OSM's API to get al the relevant geographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select   cluster_id\n",
    ",        min(latitude)\n",
    ",        min(longitude)\n",
    ",        max(latitude)\n",
    ",        max(longitude)\n",
    "from     cluster_point\n",
    "group by cluster_id\n",
    "\"\"\"\n",
    "# s, w, n, e\n",
    "bounding_boxes = {bb[0]: (bb[1], bb[2], bb[3], bb[4]) for bb in db.query(sql)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for the data sourced from OSM per cluster. This directory will contain OSM data partitioned by QuadKey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/qk-cache\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, iterate over the clusters and retrieve the respective OSM data. If the cache file does not exist, get the data from the OSM API and store it in a cluster-specific file. The conversion magic happens in the `OSMNet` class, in `./osm/models.py`. The function `from_overpass` creates an `OSMNet` object per cluster containing two collections: nodes (`OSMNode`) and ways (`OSMWay`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_osm` function queries the OSM servers for a \"rectangle\" of data delimited by the location parameters: _south_, _west_, _north_ and _east_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_osm(s, w, n, e, overpass_url =\"http://overpass-api.de/api/interpreter\"):\n",
    "    overpass_query = \"[out:json];(way[highway]{0};);(._;>;);out body;\".format((s, w, n, e))\n",
    "    response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "    osm_data = response.json()\n",
    "    return osm_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_osm_by_qk` retrieves the OSM data given a single QuadKey code. If the data is already in the cache, it is not requested again from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_by_qk(qk):\n",
    "    file_name = \"./data/qk-cache/{0}.json\".format(qk)\n",
    "    \n",
    "    if os.path.isfile(file_name):\n",
    "        with open(file_name) as f:\n",
    "            txt = f.read()\n",
    "            osm_data = json.loads(txt)\n",
    "    else:\n",
    "        sw = qk.to_geo(anchor=TileAnchor.ANCHOR_SW)\n",
    "        ne = qk.to_geo(anchor=TileAnchor.ANCHOR_NE)\n",
    "        osm_data = query_osm(sw[0], sw[1], ne[0], ne[1])\n",
    "\n",
    "        with open(file_name, \"wt\") as f:\n",
    "            f.write(json.dumps(osm_data))\n",
    "    return osm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_elements` function extracts a single type of element from an OSM dictionary. Here, we will only use the `node` and `way` types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_elements(osm, type_name):\n",
    "    return [n for n in osm[\"elements\"] if n[\"type\"] == type_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `merge_osm` function merges two OSM dictionaries into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_osm(osm0, osm1):\n",
    "    node_dict = {n[\"id\"]: n for n in get_osm_elements(osm0, \"node\")}\n",
    "    for n in get_osm_elements(osm1, \"node\"):\n",
    "        if n[\"id\"] not in node_dict:\n",
    "            node_dict[n[\"id\"]] = n\n",
    "            \n",
    "    ways0 = {w[\"id\"]: w for w in get_osm_elements(osm0, \"way\")} \n",
    "    ways1 = {w[\"id\"]: w for w in get_osm_elements(osm1, \"way\")}\n",
    "    \n",
    "    way_list = []\n",
    "    \n",
    "    for w_id in ways0.keys():\n",
    "        if w_id in ways1:\n",
    "            w0 = ways0[w_id]\n",
    "            w1 = ways1[w_id]\n",
    "            nodes = list(set(w0[\"nodes\"]).union(set(w1[\"nodes\"])))\n",
    "            way_list.append({\"type\": \"way\",\n",
    "                             \"id\": w_id,\n",
    "                             \"nodes\": nodes,\n",
    "                             \"tags\": w0[\"tags\"]})\n",
    "        else:\n",
    "            way_list.append(ways0[w_id])\n",
    "            \n",
    "    for w_id in ways1.keys():\n",
    "        if w_id not in ways0:\n",
    "            way_list.append(ways1[w_id])\n",
    "    \n",
    "    osm = {\"elements\": list(node_dict.values()) + way_list}\n",
    "    return osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `merge_osm_list` merges a list of OSM dictionaries into one. Note that only the `elements` key is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_osm_list(osm_list):\n",
    "    osm = osm_list[0]\n",
    "    for i in range(1, len(osm_list)):\n",
    "        osm = merge_osm(osm, osm_list[i])\n",
    "    return osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_cluster_qk` callculates all the unique quadkey codes corresponding to the points in a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_qk(cluster, level=18):\n",
    "    return list(set([quadkey.from_geo(p, level) for p in get_cluster_points(cluster)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_osm_data` retrieves all the OSM data for a single cluster, discretized as fixed-level QuadKeys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_data(cluster, overpass_url =\"http://overpass-api.de/api/interpreter\", level=18):\n",
    "    qk_list = get_cluster_qk(cluster, level=level)\n",
    "    osm_list = [get_osm_by_qk(qk) for qk in qk_list]\n",
    "\n",
    "    osm_data = merge_osm_list(osm_list)\n",
    "    return osm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nets = dict()    # OSMNet dict\n",
    "c_names = dict()   # Cluster name dict\n",
    "for cluster in tqdm(clusters):\n",
    "    osm_data = get_osm_data(cluster)\n",
    "\n",
    "    c_nets[cluster] = OSMNet.from_overpass(osm_data)\n",
    "        \n",
    "    points = np.array(get_cluster_points(cluster))\n",
    "    c_names[cluster] = c_nets[cluster].get_name(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_map_polygon` function below receives a list of point coordinates and plots them on a map as a closed polygon. We will use it to display the cluster's outer shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_polygon(xy, tooltip='',\n",
    "                       color='#3388ff',\n",
    "                       opacity=0.7,\n",
    "                       fill_color='#3388ff',\n",
    "                       fill_opacity=0.4, \n",
    "                       weight=3):\n",
    "    points = [[x[0], x[1]] for x in xy]\n",
    "    polygon = folium.vector_layers.Polygon(locations=points,\n",
    "                                           tooltip=tooltip,\n",
    "                                           fill=True,\n",
    "                                           color=color,\n",
    "                                           fill_color=fill_color,\n",
    "                                           fill_opacity=fill_opacity,\n",
    "                                           weight=weight,\n",
    "                                           opacity=opacity)\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_map_quadkey` function creates the map polygon for the projected square corresponding to a quadkey code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_quadkey(qk, tooltip='',\n",
    "                       color='#3388ff',\n",
    "                       opacity=0.7,\n",
    "                       fill_color='#3388ff',\n",
    "                       fill_opacity=0.4, \n",
    "                       weight=3):\n",
    "    sw = qk.to_geo(anchor=TileAnchor.ANCHOR_SW)\n",
    "    ne = qk.to_geo(anchor=TileAnchor.ANCHOR_NE)\n",
    "    s, w = sw[0], sw[1]\n",
    "    n, e = ne[0], ne[1]\n",
    "    points = [[n, e], [s, e], [s, w], [n, w]]\n",
    "    return create_map_polygon(points, tooltip=tooltip, \n",
    "                              color=color, opacity=opacity, \n",
    "                              fill_color=fill_color, fill_opacity=fill_opacity,\n",
    "                              weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_hexes(cluster_id):\n",
    "    sql = \"select h3 from cluster_point where cluster_id = ?\"\n",
    "    hexes = list({h[0] for h in db.query(sql, [cluster_id])})\n",
    "    return hexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hexagon(h):\n",
    "    geo_lst = [p for p in h3.h3_to_geo_boundary(h)]\n",
    "    geo_lst.append(geo_lst[0])\n",
    "    return np.array(geo_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_named_cluster_map(cluster_id):\n",
    "    html_map = folium.Map(prefer_canvas=True, control_scale=True, \n",
    "                          max_zoom=18, tiles=\"cartodbpositron\")\n",
    "        \n",
    "    cluster_qk = get_cluster_qk(cluster_id)\n",
    "    for qk in cluster_qk:\n",
    "        create_map_quadkey(qk, tooltip=qk, weight=1, color='red', fill_color='white', fill_opacity=0).add_to(html_map)\n",
    "    \n",
    "    bb_list = []  # List for the bounding-box calculation\n",
    "    polygons = []\n",
    "    hexes = get_cluster_hexes(cluster_id)\n",
    "    for h in hexes:\n",
    "        points = get_hexagon(h)\n",
    "        xy = [[x[1], x[0]] for x in points]\n",
    "        xy.append([points[0][1], points[0][0]])\n",
    "        polygons.append(Polygon(xy))\n",
    "        bb_list.extend(points)\n",
    "        \n",
    "    merged = cascaded_union(polygons)\n",
    "    cluster_name = c_names[cluster_id]\n",
    "    \n",
    "    for point in get_cluster_points(cluster_id):\n",
    "        CircleMarker(point, radius=1).add_to(html_map)\n",
    "    \n",
    "    if merged.geom_type == \"MultiPolygon\":\n",
    "        max_len = 0\n",
    "        largest = None\n",
    "        for geom in merged.geoms:\n",
    "            xy = geom.exterior.coords.xy\n",
    "            lxy = list(zip(xy[1], xy[0]))\n",
    "            create_map_polygon(lxy, tooltip=cluster_name).add_to(html_map)\n",
    "    elif merged.geom_type == \"Polygon\":\n",
    "        xy = merged.exterior.coords.xy\n",
    "        lxy = list(zip(xy[1], xy[0]))\n",
    "\n",
    "        create_map_polygon(lxy, tooltip=cluster_name).add_to(html_map)\n",
    "        \n",
    "    locations = np.array(bb_list)\n",
    "    min_lat, max_lat = locations[:, 0].min(), locations[:, 0].max()\n",
    "    min_lon, max_lon = locations[:, 1].min(), locations[:, 1].max()\n",
    "    html_map.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]])\n",
    "    return html_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of cluster counts from the database (_I could have used the length of the_ `bounding_boxes` _list, I know..._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select count(distinct cluster_id) from cluster_point\"\n",
    "cluster_count = db.query_scalar(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result of our efforts in an interactive fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = interact(show_named_cluster_map, cluster_id=widgets.IntSlider(min=0, max=cluster_count-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize Clusters to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now serialize the cluster names to the database. As before, we create a new table named `cluster` with the cluster identifier and its new found name. If the table already exists, we merely delete all its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists(\"cluster\"):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE cluster (\n",
    "        cluster_id      INTEGER PRIMARY KEY ASC,\n",
    "        cluster_name    TEXT\n",
    "    )\n",
    "    \"\"\"\n",
    "    db.execute_sql(sql)\n",
    "else:\n",
    "    db.execute_sql(\"DELETE FROM cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the cluster identifiers and their names to a list of tuples, the format for the bulk insertion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = [(c, c_names[c]) for c in range(cluster_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insert the data into the database using a pre-stored insert statement. You can fine the statement definition under the `/db/sql/cluster` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert_list(\"cluster/insert\", cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done. What more explorations await us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
