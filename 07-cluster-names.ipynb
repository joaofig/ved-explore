{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-Cluster Naming\n",
    "\n",
    "In this notebook we will use the locations that were used to create the clusters to match against OpenStreetMap's data in order to derive a human-readable name for each cluster. These clusters are mainly street intersections in Ann Arbor, so names will try and reflect that.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- Please run the `06-cluster-geofencing.ipynb` notebook first and its dependencies.\n",
    "- Recommended install: [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html). Enable using `jupyter nbextension enable --py widgetsnbextension --sys-prefix` for Jupyter Notebook and `jupyter labextension install @jupyter-widgets/jupyterlab-manager` for Jupyter Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import folium\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import folium\n",
    "import numpy as np\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from folium.vector_layers import PolyLine, CircleMarker\n",
    "from h3 import h3\n",
    "from sqlapi import VedDb\n",
    "from tqdm.auto import tqdm\n",
    "from osm.models import OSMNode, OSMWay, OSMNet\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object of the `VedDB` type to interface with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = VedDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_cluster_points` retrieves all the geographic locations that define a particular cluster, or endpoint. Note how the single parameter is passed enclosed in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_points(cluster):\n",
    "    sql = \"select latitude, longitude from cluster_point where cluster_id=?\"\n",
    "    return db.query(sql, [cluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the cluster identifiers from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select distinct cluster_id from cluster_point\"\n",
    "clusters = [c[0] for c in db.query(sql)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying OpenStreetMap Data\n",
    "\n",
    "In this section we calculate the cluster names using data from OpenStreetMap's [OverPass API](https://wiki.openstreetmap.org/wiki/Overpass_API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by calculating all the clusters' bounding boxes, using the code below. Each bounding box delimits the query to OSM's API to get al the relevant geographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select   cluster_id\n",
    ",        min(latitude)\n",
    ",        min(longitude)\n",
    ",        max(latitude)\n",
    ",        max(longitude)\n",
    "from     cluster_point\n",
    "group by cluster_id\n",
    "\"\"\"\n",
    "# s, w, n, e\n",
    "bounding_boxes = {bb[0]: (bb[1], bb[2], bb[3], bb[4]) for bb in db.query(sql)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for the data sourced from OSM per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/bbox\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, iterate over the clusters and retrieve the respective OSM data. If the cache file does not exist, get the data from the OSM API and store it in a cluster-specific file. The conversion magic happens in the `OSMNet` class, in `./osm/models.py`. The function `from_overpass` creates an `OSMNet` object per cluster containing two collections: nodes (`OSMNode`) and ways (`OSMWay`).\n",
    "\n",
    "The `get_osm_data` retrieves the OSM data associated with a cluster while abstracting away the file cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_data(cluster, overpass_url =\"http://overpass-api.de/api/interpreter\"):\n",
    "    file_name = \"./data/bbox/bb-{0}.json\".format(cluster)\n",
    "    \n",
    "    if os.path.isfile(file_name):\n",
    "        with open(file_name) as f:\n",
    "            txt = f.read()\n",
    "            osm_data = json.loads(txt)\n",
    "    else:\n",
    "        overpass_query = \"[out:json];(way[highway]{0};);(._;>;);out body;\".format(bounding_boxes[cluster])\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "        osm_data = response.json()\n",
    "        \n",
    "        with open(file_name, \"wt\") as f:\n",
    "            f.write(json.dumps(osm_data))\n",
    "    return osm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nets = dict()    # OSMNet dict\n",
    "c_names = dict()   # Cluster name dict\n",
    "for cluster in tqdm(clusters):\n",
    "    osm_data = get_osm_data(cluster)\n",
    "\n",
    "    c_nets[cluster] = OSMNet.from_overpass(osm_data)\n",
    "        \n",
    "    points = np.array(get_cluster_points(cluster))\n",
    "    c_names[cluster] = c_nets[cluster].get_name(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_map_polygon` function below receives a list of point coordinates and plots them on a map as a closed polygon. We will use it to display the cluster's outer shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_polygon(xy, tooltip='',\n",
    "                       color='#3388ff',\n",
    "                       opacity=0.7,\n",
    "                       fill_color='#3388ff',\n",
    "                       fill_opacity=0.4, \n",
    "                       weight=3):\n",
    "    points = [[x[0], x[1]] for x in xy]\n",
    "    polygon = folium.vector_layers.Polygon(locations=points,\n",
    "                                           tooltip=tooltip,\n",
    "                                           fill=True,\n",
    "                                           color=color,\n",
    "                                           fill_color=fill_color,\n",
    "                                           fill_opacity=fill_opacity,\n",
    "                                           weight=weight,\n",
    "                                           opacity=opacity)\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_hexes(cluster_id):\n",
    "    sql = \"select h3 from cluster_point where cluster_id = ?\"\n",
    "    hexes = list({h[0] for h in db.query(sql, [cluster_id])})\n",
    "    return hexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hexagon(h):\n",
    "    geo_lst = [p for p in h3.h3_to_geo_boundary(h)]\n",
    "    geo_lst.append(geo_lst[0])\n",
    "    return np.array(geo_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_named_cluster_map(cluster_id):\n",
    "    html_map = folium.Map(prefer_canvas=True, control_scale=True, \n",
    "                          max_zoom=18, tiles=\"cartodbpositron\")\n",
    "    \n",
    "    bb_list = []  # List for the bounding-box calculation\n",
    "    polygons = []\n",
    "    hexes = get_cluster_hexes(cluster_id)\n",
    "    for h in hexes:\n",
    "        points = get_hexagon(h)\n",
    "        xy = [[x[1], x[0]] for x in points]\n",
    "        xy.append([points[0][1], points[0][0]])\n",
    "        polygons.append(Polygon(xy))\n",
    "        bb_list.extend(points)\n",
    "        \n",
    "    merged = cascaded_union(polygons)\n",
    "    cluster_name = c_names[cluster_id]\n",
    "    \n",
    "    for point in get_cluster_points(cluster_id):\n",
    "        CircleMarker(point, radius=1).add_to(html_map)\n",
    "    \n",
    "    if merged.geom_type == \"MultiPolygon\":\n",
    "        max_len = 0\n",
    "        largest = None\n",
    "        for geom in merged.geoms:\n",
    "            xy = geom.exterior.coords.xy\n",
    "            lxy = list(zip(xy[1], xy[0]))\n",
    "            create_map_polygon(lxy, tooltip=cluster_name).add_to(html_map)\n",
    "    elif merged.geom_type == \"Polygon\":\n",
    "        xy = merged.exterior.coords.xy\n",
    "        lxy = list(zip(xy[1], xy[0]))\n",
    "\n",
    "        create_map_polygon(lxy, tooltip=cluster_name).add_to(html_map)\n",
    "        \n",
    "    locations = np.array(bb_list)\n",
    "    min_lat, max_lat = locations[:, 0].min(), locations[:, 0].max()\n",
    "    min_lon, max_lon = locations[:, 1].min(), locations[:, 1].max()\n",
    "    html_map.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]])\n",
    "    return html_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of cluster counts from the database (_I could have used the length of the_ `bounding_boxes` _list, I know..._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select count(distinct cluster_id) from cluster_point\"\n",
    "cluster_count = db.query_scalar(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result of our efforts in an interactive fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = interact(show_named_cluster_map, cluster_id=widgets.IntSlider(min=0, max=cluster_count-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize Clusters to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now serialize the cluster names to the database. As before, we create a new table named `cluster` with the cluster identifier and its new found name. If the table already exists, we merely delete all its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists(\"cluster\"):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE cluster (\n",
    "        cluster_id      INTEGER PRIMARY KEY ASC,\n",
    "        cluster_name    TEXT\n",
    "    )\n",
    "    \"\"\"\n",
    "    db.execute_sql(sql)\n",
    "else:\n",
    "    db.execute_sql(\"DELETE FROM cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the cluster identifiers and their names to a list of tuples, the format for the bulk insertion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = [(c, c_names[c]) for c in range(cluster_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insert the data into the database using a pre-stored insert statement. You can fine the statement definition under the `/db/sql/cluster` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert_list(\"cluster/insert\", cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done. What more explorations await us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
