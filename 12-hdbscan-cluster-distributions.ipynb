{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c24bf5-bb22-42c5-ae26-7eff4a1ee2c2",
   "metadata": {},
   "source": [
    "# 12-HDBSCAN-Generated Cluster Metric Distributions\n",
    "\n",
    "In this notebook we determine a metric for HDBSCAN-generated clusters. This metric is a surrogate for the missing DBSCAN's Îµ parameter that determines the maximum reachability distance for points in the cluster. Deriving such a metric is useful when determining H3 hexagon sizes to seamlessly cover the cluster, the inflate size for a concave hull-generated shape, or the maximum radius for bubble shaping.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- Please run the `05-clustering-hdbscan.ipynb` notebook first and its dependencies.\n",
    "- Recommended install: [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html). Enable using `jupyter nbextension enable --py widgetsnbextension --sys-prefix` for Jupyter Notebook and `jupyter labextension install @jupyter-widgets/jupyterlab-manager` for Jupyter Lab.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373232f8-f242-485e-9d3a-b3d288828e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from db.api import VedDb\n",
    "from itertools import groupby\n",
    "from tqdm import trange, tqdm\n",
    "from fitter import Fitter, get_common_distributions\n",
    "from geo.math import vec_haversine, square_haversine, num_haversine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a093e-0881-46fb-b912-2eec81e981c4",
   "metadata": {},
   "source": [
    "The function `get_graph_distances` uses the location array to calculate the list of minimum distances using the network theory approach. It starts by calculating the distance matrix. Next it build the undirected graph with the distances as edge weights. Finally, it determines the minimum soanning tree and returns the associated distances as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbd2de-bbb4-4642-977f-449f1e5c87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_mst_minimums(locations):\n",
    "    n = locations.shape[0]\n",
    "    g = nx.Graph()\n",
    "    \n",
    "    dist = square_haversine(locations[:, 0], locations[:, 1])\n",
    "\n",
    "    g.add_nodes_from(range(locations.shape[0]))\n",
    "    g.add_edges_from([(i, j, {'weight': dist[i, j]}) for i in range(n) for j in range(i + 1, n)])\n",
    "            \n",
    "    mst = nx.minimum_spanning_tree(g, algorithm='prim', weight=\"weight\")\n",
    "    min_dist = [dist[e[0], e[1]] for e in mst.edges()]\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94eaa4-d32f-440e-a6c3-fecbe062a884",
   "metadata": {},
   "source": [
    "Declare the database object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71d1d3-d2c2-482b-a93d-1ef9294bf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = VedDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35e788-3cbb-4445-aeb7-405ca9e86f2a",
   "metadata": {},
   "source": [
    "Get all cluster identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e851f5e-af34-41fe-ae96-78d624b925d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select cluster_id from cluster\"\n",
    "cluster_ids = [c[0] for c in db.query(sql)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea694c-fe82-49d7-aca4-44c2f0cddb5e",
   "metadata": {},
   "source": [
    "The code below iterates through all clusters and determines the respective minimum spanning tree weight distribution. Next it uses the `fitter` package to determine what is the distribution type that better fits the distances, and appends the best one to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7eeecc-33fa-4b5b-875b-63c6f2b7ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for c in tqdm(cluster_ids):\n",
    "    c_locs = db.get_cluster_locations(c)\n",
    "    min_ws = get_graph_mst_minimums(c_locs)\n",
    "    fitter = Fitter(min_ws, distributions=get_common_distributions())\n",
    "    fitter.fit()\n",
    "    dists.append(fitter.get_best())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb1f9e-57a2-4acb-be2f-6074fb878325",
   "metadata": {},
   "source": [
    "Now, we get the sorted list of the distribution names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500cfc7-35d8-40c5-a981-a681c7a413ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sorted([list(d.keys())[0] for d in dists])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5c82c-8209-4ec1-927b-d8632f146cb5",
   "metadata": {},
   "source": [
    "Finally, we count the distribution names and present the results as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b339ed-8195-4a04-9b08-e4a6c1369dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_data = [[key, len(list(group))] for key, group in groupby(names)]\n",
    "dist_df = pd.DataFrame(data=dist_data, columns=[\"Distribution\", \"Count\"])\n",
    "dist_df[\"Percent\"] = dist_df[\"Count\"] / dist_df[\"Count\"].sum() * 100\n",
    "dist_df.sort_values([\"Count\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8400c-4556-46f8-aa63-0073cfb0395c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
